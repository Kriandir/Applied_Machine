{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np  # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import operator\n",
    "\n",
    "assert os.path.exists('./emails.train.csv'), \"[Dataset File Not Found] Please download dataset first.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                                               text  spam\n",
      "0   0  Subject: naturally irresistible your corporate...     1\n",
      "1   2  Subject: unbelievable new homes made easy  im ...     1\n",
      "2   3  Subject: 4 color printing special  request add...     1\n",
      "3   4  Subject: do not have money , get software cds ...     1\n",
      "4   5  Subject: great nnews  hello , welcome to medzo...     1\n",
      "415\n",
      "0.23700571997015668\n",
      "0.23700571997\n"
     ]
    }
   ],
   "source": [
    "# Read in csv file as dataframe\n",
    "df = pd.read_csv('./emails.train.csv')\n",
    "zf = pd.read_csv('./emails.test.csv')\n",
    "\n",
    "# Show a snippet of dataset.\n",
    "print(df.head())\n",
    "print(np.sum(zf['spam']))\n",
    "\n",
    "spamappend = 0\n",
    "hamappend = 0\n",
    "for i in df[\"spam\"]:\n",
    "    if i == 1:\n",
    "        spamappend += 1\n",
    "    if i == 0:\n",
    "        hamappend +=1\n",
    "\n",
    "probspam = float(spamappend)/(spamappend+hamappend)\n",
    "print(probspam)\n",
    "spam = sum(df[\"spam\"])\n",
    "ham =  len(df[\"spam\"])-sum(df[\"spam\"])\n",
    "probspam = float(spam)/(spam+ham)\n",
    "print(probspam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Clean training data ==========\n",
      "Cleaning text...\n",
      "========= Clean testing data ==========\n",
      "Cleaning text...\n",
      "Cleaned the data\n"
     ]
    }
   ],
   "source": [
    "def cleaning_text(dataframe):\n",
    "    print('Cleaning text...')\n",
    "    import re\n",
    "    \n",
    "    for i, line in enumerate(dataframe['text']):\n",
    "        \n",
    "        # remove special characters using regex\n",
    "        line = re.sub(r'[^\\w]', ' ', line).lower()\n",
    "        # remove numeric characters using regex\n",
    "        line = re.sub(\"(^|\\W)\\d+($|\\W)\", \" \", line)\n",
    "           \n",
    "        # remove words of two characters or less\n",
    "        words = line.split()\n",
    "        resultwords = []\n",
    "        \n",
    "        for word in words:\n",
    "            if len(word) > 2:\n",
    "                resultwords.append(word)\n",
    "                \n",
    "        newline = ' '.join(resultwords)\n",
    "\n",
    "        dataframe.loc[i, 'text'] = newline\n",
    "\n",
    "    return dataframe\n",
    "        \n",
    "print('========= Clean training data ==========')\n",
    "# Read in training data\n",
    "df = pd.read_csv('./emails.train.csv')\n",
    "\n",
    "# Do cleaning\n",
    "df = cleaning_text(df)\n",
    "\n",
    "# Save as new file\n",
    "df.to_csv('emails_clean.train.csv')\n",
    "\n",
    "print('========= Clean testing data ==========')\n",
    "# Read in testing data\n",
    "df = pd.read_csv('./emails.test.csv')\n",
    "\n",
    "# Do cleaning\n",
    "df = cleaning_text(df)\n",
    "\n",
    "# Save as new file\n",
    "df.to_csv('emails_clean.test.csv')\n",
    "\n",
    "print('Cleaned the data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve word frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get word frequency data for both train data\n",
    "def word_frequency_train(dataframe):\n",
    "    # for w in dataframe.str.lower():\n",
    "#     create a dataframe of all words\n",
    "    \n",
    "    datasetwords = {}\n",
    "    \n",
    "    for line in dataframe[\"text\"]:\n",
    "        words = line.split()\n",
    "        for word in words:\n",
    "            if word in datasetwords:\n",
    "                datasetwords[word] += 1\n",
    "            else:\n",
    "                datasetwords[word] = 1\n",
    "    \n",
    "    return datasetwords\n",
    "\n",
    "# get word frequency data for mails\n",
    "def word_frequency_mail(mail):\n",
    "    words = mail.split()\n",
    "    datasetwords = {}\n",
    "    for word in words:\n",
    "        if word in datasetwords:\n",
    "            datasetwords[word] += 1\n",
    "        else:\n",
    "            datasetwords[word] = 1\n",
    "    \n",
    "    return datasetwords    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# freqsword = frequency word in spam, freqhword is frequency word in ham\n",
    "def NaiveBayesian(probspam,freqsword,freqhword,totalfreqs,totalfreqh):\n",
    "    \n",
    "#   probability of a mail being ham \n",
    "    probham = 1-probspam\n",
    "    \n",
    "#   calculate probability of word being in spam or word being in spam\n",
    "    probwordspam = float(freqsword)/(totalfreqs)\n",
    "    probwordham = float(freqhword)/(totalfreqh)\n",
    "    bayes = (float(probwordspam*probspam)/(probwordspam*probspam + probwordham*probham))\n",
    "\n",
    "\n",
    "#       equation for correcting the probability where s =3 means that meaning that the learned dictionary\n",
    "#       must contain more than 3 messages with the word\n",
    "    s = 3\n",
    "    correctedbayes = float(s*probspam+freqsword*bayes)/(s+freqsword)\n",
    "    \n",
    "#   if the spamicity of the word is around 0.5 return none since the probability of the word being ham or spam\n",
    "#   is too similar so we evaluate only spammicities of <=0.2 and >= 0.8\n",
    "    \n",
    "    if correctedbayes >= 0.8 or bayes <=0.2:\n",
    "        return correctedbayes\n",
    "\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Here we call our Naive Bayesian performer with the data we read in from train and test and check\n",
    "# if the test mail is spam or not\n",
    "def CallBae(freqspam,freqham,mail,probspam,totalfreqs,totalfreqh):\n",
    "    spamchecklist = []\n",
    "    \n",
    "    for word in mail:\n",
    "    \n",
    "#     if word in spam and ham check its frequency and perform the Bayesian as many times as needed\n",
    "        if word in freqspam and word in freqham:\n",
    "            for i in range(mail[word]):\n",
    "                freqsword = freqspam[word]\n",
    "                freqhword = freqham[word]\n",
    "                spamchecklist.append(NaiveBayesian(probspam,freqsword,freqhword,totalfreqs,totalfreqh))\n",
    "\n",
    "    #   if the word is in neither spam or ham we continue the word iteration\n",
    "        elif word not in freqspam and word not in freqham:\n",
    "            continue\n",
    "\n",
    "    #  we initialize freqsword as a tiny number here cause else the Bayesian would not be able to pick up that \n",
    "    #  the word is in ham if the word never appears in spam but does appear in ham\n",
    "        elif word in freqham and word not in freqspam:\n",
    "            for i in range(mail[word]):\n",
    "                freqsword = 10**(-8)\n",
    "                freqhword = freqham[word]\n",
    "                spamchecklist.append(NaiveBayesian(probspam,freqsword,freqhword,totalfreqs,totalfreqh))\n",
    "\n",
    "            \n",
    "#   Clean up the spamchecklist\n",
    "    spamchecklist = np.array(spamchecklist)\n",
    "    spamchecklist = spamchecklist[spamchecklist != np.array(None)]\n",
    "    \n",
    "################################################################\n",
    "#    Again zou eigenlijk correct meoten zijn maar werkt niet (dit selecteert van de data alleen de 10 beste entries)\n",
    "#     try:\n",
    "#         spamchecklist = np.take(spamchecklist,(np.argpartition(abs(0.5-spamchecklist), -10)[-10:]))\n",
    "#     except:\n",
    "#         spamchecklist = spamchecklist\n",
    "#  #####################################################################   \n",
    "\n",
    "    \n",
    "#   Count all probabilities in spamchecklist and calculate the overal probability of the mail being spam or ham\n",
    "    multiplicationsum = np.prod(spamchecklist)\n",
    "    ones = np.ones(spamchecklist.shape)\n",
    "    pminusonesum = np.prod(ones-spamchecklist)\n",
    "    \n",
    "#   Make sure we won't have conflicts with machine precision for if the mail is almost certainly spam we get very\n",
    "#   small numbers which add to 0 under machine precision\n",
    "    if pminusonesum + multiplicationsum ==0:\n",
    "        finaljudge = 1\n",
    "    else:   \n",
    "        finaljudge = multiplicationsum/(multiplicationsum+pminusonesum)\n",
    "        \n",
    "#########################################\n",
    "# DIT WERKT SOMEHOW BETER maar theoretisch onjuist dus niet super handig te gebruiken (voor de overal probability te berekenen)\n",
    "#     finaljudge = sum(spamchecklist/len(spamchecklist))\n",
    "###############################################\n",
    "    \n",
    "#   Return False if spam\n",
    "    if finaljudge > 0.5:\n",
    "        return True\n",
    "#   Return True if ham\n",
    "    if finaljudge < 0.5:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Takes as input frequency table of spam words, frequency table of ham words,the mail we have to check,\n",
    "# probability mail is spam, total frequency of words in spam and total frequency of words  in  ham\n",
    "def Classifier(freqspam,freqham,test,probspam,totalfreqs,totalfreqh,train):\n",
    "    iddict = {}\n",
    "    spamdict = {}\n",
    "    idlist = []\n",
    "    spamlist = [] \n",
    "    \n",
    "# loop through all the mails in the test and perform naive bayesian and add id number to the list\n",
    "    for i in range(len(test)):\n",
    "        idlist.append(test['id'][i])\n",
    "        mail = test['text'][i]        \n",
    "        mail = word_frequency_mail(mail)\n",
    "    \n",
    "#         if we get True from CallBae mail is spam and we add it to the spam dictionary\n",
    "        if CallBae(freqspam,freqham,mail,probspam,totalfreqs,totalfreqh):\n",
    "            spamlist.append(1)\n",
    "\n",
    "            freqspam = combine_dicts(freqspam,mail)\n",
    "            totalfreqs = sum(freqspam.values())      \n",
    "    \n",
    "#             If we get False from Callbae mail is added to ham dictionary and defined as ham\n",
    "        else:\n",
    "            spamlist.append(0)\n",
    "            freqham = combine_dicts(freqham,mail)\n",
    "            totalfreqh = sum(freqham.values())\n",
    "                   \n",
    "    \n",
    "#   create our submission with per id the indicator whether the mail is spam or not (1 or 0)\n",
    "    spamdict['spam'] = spamlist\n",
    "    iddict['id'] = idlist\n",
    "    spamdict = pd.DataFrame(dict([(k,pd.Series(v)) for k,v in spamdict.items()]))\n",
    "    iddict = pd.DataFrame(dict([(k,pd.Series(v)) for k,v in iddict.items()]))\n",
    "    submission = pd.concat([iddict,spamdict],axis = 1)\n",
    "    submission.set_index('id',inplace=True)\n",
    "    submission.to_csv('submission.csv')\n",
    "    return submission,idlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function for combining dictionaries\n",
    "def combine_dicts(a, b, op=operator.add):\n",
    "    return dict(a.items() + b.items() +[(k, op(a[k], b[k])) for k in set(b) & set(a)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'dict_items' and 'dict_items'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-8ccf378fbbe6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m# Call our  model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0msubmission\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0midlist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfreqspam\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfreqham\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprobspam\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtotalfreqs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtotalfreqh\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-37-262293cdaad0>\u001b[0m in \u001b[0;36mClassifier\u001b[1;34m(freqspam, freqham, test, probspam, totalfreqs, totalfreqh, train)\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mspamlist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m             \u001b[0mfreqspam\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcombine_dicts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfreqspam\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmail\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m             \u001b[0mtotalfreqs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfreqspam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-41-0db5b7081c4f>\u001b[0m in \u001b[0;36mcombine_dicts\u001b[1;34m(a, b, op)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# function for combining dictionaries\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcombine_dicts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moperator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'dict_items' and 'dict_items'"
     ]
    }
   ],
   "source": [
    "# intialize initials\n",
    "train = pd.read_csv('./emails_clean.train.csv')\n",
    "test  = pd.read_csv('./emails_clean.test.csv')\n",
    "hamdata = train[train.spam == 0]\n",
    "spamdata = train[train.spam == 1]\n",
    "freqham = word_frequency_train(hamdata)\n",
    "freqspam = word_frequency_train(spamdata)\n",
    "totalfreqs = sum(freqspam.values())\n",
    "totalfreqh = sum(freqham.values())\n",
    "spam = sum(train[\"spam\"])\n",
    "ham =  len(train[\"spam\"])-sum(train[\"spam\"])\n",
    "probspam = 0.5\n",
    "##################################################################\n",
    "# DEZE HEURISTIEK WERKT VOOR GENE METER DUS HOUD PROBSPAM op 0.5\n",
    "# probspam = float(spam)/float(ham+spam)\n",
    "###############################################################\n",
    "\n",
    "# Call our  model\n",
    "submission,idlist = Classifier(freqspam,freqham,test,probspam,totalfreqs,totalfreqh,train)\n",
    "\n",
    "\n",
    "# MEAN CONSEQUENTIAL EVALUATER:\n",
    "\n",
    "ms = 0\n",
    "test.set_index('id',inplace=True)\n",
    "for i in idlist:\n",
    "    try:      \n",
    "        if test[\"spam\"][i] != submission[\"spam\"][i]:\n",
    "            ms +=1\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "MCE = 1./submission.shape[0]*ms\n",
    "\n",
    "print(MCE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
